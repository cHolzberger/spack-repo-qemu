From 683b232fa212fb5f00b4b9b9c205146214b3ac64 Mon Sep 17 00:00:00 2001
From: Saverio Miroddi <saverio.pub2@gmail.com>
Date: Fri, 12 Jul 2019 11:23:36 +0200
Subject: [PATCH 1/4] Allow symlinks in Samba share

---
 net/slirp.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/net/slirp.c b/net/slirp.c
index 77042e6df74..8c6b21eb058 100644
--- a/net/slirp.c
+++ b/net/slirp.c
@@ -867,6 +867,8 @@ static int slirp_smb(SlirpState* s, const char *exported_dir,
             "printing = bsd\n"
             "disable spoolss = yes\n"
             "usershare max shares = 0\n"
+            "follow symlinks = yes\n"
+            "wide links = yes\n"
             "[qemu]\n"
             "path=%s\n"
             "read only=no\n"

From c0ae6f6c9851ab80802eac5aa310c144e519b4fb Mon Sep 17 00:00:00 2001
From: Saverio Miroddi <saverio.pub2@gmail.com>
Date: Thu, 11 Jan 2018 19:59:17 +0100
Subject: [PATCH 2/4] Add README.md and build_pinning_qemu_binary.sh; update
 .gitignore (add `/bin`)

---
 .gitignore                   |   1 +
 README.md                    | 160 +++++++++++++++++++++++++++++++++++
 build_pinning_qemu_binary.sh |  79 +++++++++++++++++
 3 files changed, 240 insertions(+)
 create mode 100644 README.md
 create mode 100755 build_pinning_qemu_binary.sh

diff --git a/.gitignore b/.gitignore
index 0c5af83aa74..9720763327b 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,3 +1,4 @@
+/bin
 /.doctrees
 /config-devices.*
 /config-all-devices.*
diff --git a/README.md b/README.md
new file mode 100644
index 00000000000..e02c60bfe9f
--- /dev/null
+++ b/README.md
@@ -0,0 +1,160 @@
+# QEMU-Pinning: QEMU fork with pinning (affinity) support
+
+Fork of QEMU, with support for pinning virtual cpus/cores/threads to the physical counterparts.
+
+## Table of contents
+
+- [Patch notes](#patch-notes)
+- [Building the project (including QEMU binary)](#building-the-project-including-qemu-binary)
+  - [Generic execution](#generic-execution)
+  - [More advanced execution](#more-advanced-execution)
+  - [Verifying the pinning](#verifying-the-pinning)
+  - [Multi-socket CPUs](#multi-socket-cpus)
+- [Repository (git) structure](#repository-git-structure)
+- [Why not libvirt?](#why-not-libvirt)
+
+## Patch notes
+
+The code was originally a QEMU 2.4.1 patch [published on the QEMU mailing list](https://www.mail-archive.com/qemu-discuss%40nongnu.org/msg02253.html); I've made significant fixes/cleanups, and I periodically rebase/update it on top of the release QEMU versions.
+
+Pinning is accomplished using the Linux interfaces `cpu_set_t` (and related macros) and `pthread_setaffinity_np`.
+
+## Building the project (including QEMU binary)
+
+A script is provided for building the project on common Linux distros. The master branch is always the most recent QEMU release version (or at least, a very recent one), so it's appropriate for general use.
+
+From the project root, run:
+
+```sh
+./build_pinning_qemu_binary.sh
+```
+
+The project will be built, and display the binary location.
+
+A few important notes:
+
+- this is a rather minimal build configuration, and it won't have any secondary feature aside the mentioned ones (GTK VGA, Pulseaudio, and USB); if you need more features, you can easily alter the `./configure` command in the build script;
+- the project itself is composed of many components, so copying the binary itself to another location will not work.
+
+It's trivial to adjust the script to run it on other distributions.
+
+### Generic execution
+
+Pinning (-related) QEMU options:
+
+```
+-smp <total_vcpus>,cores=<vcores>,sockets=<vsockets>,threads=<vthreads>
+-vcpu vcpunum=<vcpu_number>,affinity=<host_cpu_number>
+```
+
+Convenient bash script to assign one virtual CPU per core (*not per thread*):
+
+```sh
+CORES_NUMBER=$(lscpu --all -p=CORE | grep -v ^# | sort | uniq | wc -l)
+
+SMP_PARAMS="-smp $CORES_NUMBER,cores=$CORES_NUMBER,sockets=1,threads=1"
+
+for core_number in $(seq 1 $CORES_NUMBER); do
+  PINNING_PARAMS=" $PINNING_PARAMS -vcpu vcpunum=$((core_number - 1)),affinity=$((core_number - 1))"
+done
+
+$QEMU_BINARY_PATH $SMP_PARAMS $PINNING_PARAMS $OTHER_PARAMS
+```
+
+### More advanced execution
+
+It's possible to have more complex configurations. For example, a typical configuration is to give all cores (and threads) to the guest, with the exception of one core.
+
+First, one needs to obtain the host cpu layout; a simple way is:
+
+```sh
+$ lscpu --extended
+
+CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ    MINMHZ
+0   0    0      0    0:0:0:0       yes    4200,0000 800,0000
+1   0    0      1    1:1:1:0       yes    4200,0000 800,0000
+2   0    0      2    2:2:2:0       yes    4200,0000 800,0000
+3   0    0      3    3:3:3:0       yes    4200,0000 800,0000
+4   0    0      0    0:0:0:0       yes    4200,0000 800,0000
+5   0    0      1    1:1:1:0       yes    4200,0000 800,0000
+6   0    0      2    2:2:2:0       yes    4200,0000 800,0000
+7   0    0      3    3:3:3:0       yes    4200,0000 800,0000
+```
+
+`CPU` represents a CPU from a Linux perspective, therefore, if the CPU supports SMT ("Hyper-threading" on Intel), each `CPU` is a thread.  
+In this case, for example, `CORE 0` will have two threads, represented by `CPU 0` and `CPU 4`.
+
+With the configuration above, and the objective of passing all except one core, the pinning parameters are:
+
+```
+-smp 6,cores=3,sockets=1,threads=2
+-vcpu vcpunum=0,affinity=1 -vcpu vcpunum=1,affinity=5
+-vcpu vcpunum=2,affinity=2 -vcpu vcpunum=3,affinity=6
+-vcpu vcpunum=4,affinity=3 -vcpu vcpunum=5,affinity=7
+```
+
+Such configuration will yield, in a Windows guest, 3 physical processors with 2 logical processors each, mapped to the host `CPU`s (1,5), (2,6) and (3,7).
+
+Note that according to this this result, QEMU exposes the threads (vcpus) sequentially, and Windows interprets physical processors as contiguous blocks.
+
+The configuration above can be be automated with an interesting exercise in scripting:
+
+```sh
+# Exclude the core 0, and cluster the threads, sorted by (socket,core)
+CPUS_DATA=$(lscpu --all --parse=SOCKET,CORE,CPU | grep -vP '^(#|0,0)' | sort -t ',' -n)
+
+THREADS=$(echo "$CPUS_DATA" | wc -l)
+CORES=$(echo "$CPUS_DATA" | cut -d ',' -f 2 | sort | uniq | wc -l)
+SOCKETS=$(echo "$CPUS_DATA" | cut -d ',' -f 1 | sort | uniq | wc -l)
+
+QEMU_SMP="-smp $THREADS,cores=$CORES,threads=$(($THREADS / $CORES))"
+
+vcpu=0; while read cpu_entry; do
+  affinity=$(echo $cpu_entry | cut -d ',' -f 3)
+  QEMU_AFFINITIES="$QEMU_AFFINITIES -vcpu vcpunum=$vcpu,affinity=$affinity"
+  vcpu=$(($vcpu + 1))
+done <<< "$CPUS_DATA"
+
+echo "$QEMU_SMP $QEMU_AFFINITIES"
+```
+
+### Verifying the pinning
+
+Pinning can be verified in many ways.
+
+An easy one is to use `htop` on the host, and the Microsoft-advised [Cpu Stress tool](https://blogs.msdn.microsoft.com/vijaysk/2012/10/26/tools-to-simulate-cpu-memory-disk-load) on the guest, then rotate the affinity via Task Manager.
+
+The procedure is:
+
+- run `htop` on the host
+- start the guest
+- run the CPI Stress tool, using 1 thread active, with `Maximum` activity
+- open the Task manager, `Details` tab
+- right click on `CPUSTRES.EXE`
+- now set one CPU at a time, and check which CPU will have 100% occupation on the host
+
+Don't forget that `htop` CPU indexes equal to Linux + 1!
+
+### Multi-socket CPUs
+
+This patch should also support sockets, but it can't be tested on my machine(s).
+
+## Repository (git) structure
+
+The master branch is always the latest QEMU release version (generally, with a lag of a few days, unless there are specific issues).
+
+The HEAD commit is the pinning patch, and HEAD~ contains the `README.md` and `build_pinning_qemu_binary.sh` (plus, updates to `.gitignore`).
+
+I provide branches for past versions, and for the current version (which matches `master`); they're named `vx.x.x-pinning`, and have the same structure; therefore, in order to build an older version, just checkout the branch and run the build script.
+
+## Why not libvirt?
+
+I've found libvirt to be a very interesting idea, but ultimately, a leaky abstraction:
+
+1. the compatibility with all the QEMU versions is not guaranteed (for example, v2.10 wasn't supported for some time after release);
+2. the typical GUI (`virt-manager`) is poor (many entries must be edited via `virsh edit`);
+3. since the ultimate reference is QEMU, one ends up thinking how to make things work with QEMU, then finding the libvirt configuration counterpart.
+
+Point 3 may be caused by my poor libvirt knowledge, but the fact that libvirt's functionality is built on top of QEMU always stands, and complex QEMU configurations are bound to have translation challenges.
+
+I'm sure of course, that for simple setups, `libvirt` + `virt-manager` may work very well.
diff --git a/build_pinning_qemu_binary.sh b/build_pinning_qemu_binary.sh
new file mode 100755
index 00000000000..5464af73f8f
--- /dev/null
+++ b/build_pinning_qemu_binary.sh
@@ -0,0 +1,79 @@
+#!/bin/bash
+
+set -o errexit
+
+c_binary="bin/debug/native/x86_64-softmmu/qemu-system-x86_64"
+
+echo "Hello! This script will compile the QEMU project.
+
+If the required libraries are not installed, the sudo prompt will be shown in order to proceed to the installation.
+
+The script has been tested on the following operating systems:
+
+- Ubuntu 16.04
+- Linux Mint 19 (based on Ubuntu 18.04)
+- Fedora 28
+
+it may work on other versions, and other distros (eg. Debian/RHEL).
+
+Press any key to continue..."
+
+read -rsn1
+
+# ID_LIKE would be a better choice, however, Fedora includes only ID.
+os_id=$(perl -ne 'print "$1" if /^ID=(.*)/' /etc/os-release)
+
+case $os_id in
+ubuntu|debian|linuxmint)
+  c_required_packages="flex libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev libgtk-3-dev libpulse-dev libusb-1.0-0-dev libusbredirparser-dev libspice-protocol-dev libspice-server-dev"
+  package_manager_binary=apt-get
+  ;;
+fedora|rhel)
+  c_required_packages="flex libusbx-devel spice-server-devel pulseaudio-libs-devel git gtk3-devel glib2-devel libfdt-devel pixman-devel zlib-devel libaio-devel libcap-devel libiscsi-devel"
+  package_manager_binary=yum
+  ;;
+*)
+  echo
+  echo "Unsupported operating system (ID=$os_id)!"
+  exit 1
+  ;;
+esac
+
+v_packages_to_install=""
+
+for package in $c_required_packages; do
+  if [[ ! $(dpkg -s "$package" 2> /dev/null) ]]; then
+    v_packages_to_install+=" $package"
+  fi
+done
+
+if [[ "$v_packages_to_install" != "" ]]; then
+  echo
+  sudo "$package_manager_binary" install $v_packages_to_install
+fi
+
+echo
+
+# Using a higher number of jobs, on an i7-6700k, didn't produce any significant improvement,
+# but YMMV.
+THREADS_NUMBER=$(lscpu --all -p=CPU | grep -v ^# | sort | uniq | wc -l)
+
+rm -rf bin
+mkdir -p bin/debug/native
+
+cd bin/debug/native
+../../../configure --target-list=x86_64-softmmu --enable-gtk --enable-spice --audio-drv-list=pa
+time make -j $THREADS_NUMBER
+cd -
+
+echo
+echo 'The project is built!'
+echo
+echo "The binary location is: $c_binary"
+echo
+echo "Test execution result:"
+echo
+
+$c_binary --version
+
+echo

From 205dca0c20e36ae8a14e0ab0524fc055094b4bfb Mon Sep 17 00:00:00 2001
From: Saverio Miroddi <saverio.pub2@gmail.com>
Date: Fri, 16 Aug 2019 15:09:21 +0200
Subject: [PATCH 3/4] Pinning patch for v5.0.0-rc4

Changes:

- None (same as v4.1.0)
---
 cpus.c              | 10 ++++++++++
 hw/core/machine.c   | 32 ++++++++++++++++++++++++++++++++
 include/hw/boards.h |  2 ++
 qemu-options.hx     | 10 ++++++++++
 softmmu/vl.c        | 35 +++++++++++++++++++++++++++++++++++
 5 files changed, 89 insertions(+)

diff --git a/cpus.c b/cpus.c
index ef441bdf622..8e03681e67f 100644
--- a/cpus.c
+++ b/cpus.c
@@ -1998,6 +1998,10 @@ static void qemu_hax_start_vcpu(CPUState *cpu)
 static void qemu_kvm_start_vcpu(CPUState *cpu)
 {
     char thread_name[VCPU_THREAD_NAME_SIZE];
+    cpu_set_t cpuset;
+
+    MachineState *ms = MACHINE(qdev_get_machine());
+    MachineClass *mc = MACHINE_GET_CLASS(ms);
 
     cpu->thread = g_malloc0(sizeof(QemuThread));
     cpu->halt_cond = g_malloc0(sizeof(QemuCond));
@@ -2006,6 +2010,12 @@ static void qemu_kvm_start_vcpu(CPUState *cpu)
              cpu->cpu_index);
     qemu_thread_create(cpu->thread, thread_name, qemu_kvm_cpu_thread_fn,
                        cpu, QEMU_THREAD_JOINABLE);
+
+    if (mc->vcpu_affinity[cpu->cpu_index] != -1) {
+      CPU_ZERO(&cpuset);
+      CPU_SET(mc->vcpu_affinity[cpu->cpu_index], &cpuset);
+      pthread_setaffinity_np((cpu->thread)->thread, sizeof(cpu_set_t), &cpuset);
+    }
 }
 
 static void qemu_hvf_start_vcpu(CPUState *cpu)
diff --git a/hw/core/machine.c b/hw/core/machine.c
index c1a444cb755..9a5a32784fc 100644
--- a/hw/core/machine.c
+++ b/hw/core/machine.c
@@ -768,6 +768,34 @@ static void smp_parse(MachineState *ms, QemuOpts *opts)
     }
 }
 
+static int vcpu_parse(MachineState *ms, QemuOpts *opts)
+{
+    MachineClass *mc = MACHINE_GET_CLASS(ms);
+
+    int num_affinity = 0;
+
+    if (opts) {
+        unsigned vcpu = qemu_opt_get_number(opts, "vcpunum", 0);
+        unsigned affinity = qemu_opt_get_number(opts,"affinity", 0);
+
+        if (vcpu < ms->smp.cpus * ms->smp.cores * ms->smp.threads) {
+            if (mc->vcpu_affinity[vcpu] == -1) {
+                mc->vcpu_affinity[vcpu] = affinity;
+            }
+            else {
+                error_report("Duplicate affinity statement for vcpu %d\n", vcpu);
+                return -1;
+            }
+            num_affinity += 1;
+        }
+        else {
+            error_report("VCPU %d is more than allowed %d VCPUs in the system\n", vcpu, ms->smp.cores);
+            return -1;
+        }
+    }
+    return 0;
+}
+
 static void machine_class_init(ObjectClass *oc, void *data)
 {
     MachineClass *mc = MACHINE_CLASS(oc);
@@ -776,6 +804,10 @@ static void machine_class_init(ObjectClass *oc, void *data)
     mc->default_ram_size = 128 * MiB;
     mc->rom_file_has_mr = true;
     mc->smp_parse = smp_parse;
+    mc->vcpu_parse = vcpu_parse;
+
+    for (int i = 0; i < CPU_SETSIZE; i++)
+        mc->vcpu_affinity[i] = -1;
 
     /* numa node memory size aligned on 8MB by default.
      * On Linux, each node's border has to be 8MB aligned
diff --git a/include/hw/boards.h b/include/hw/boards.h
index fd4d62b5010..7956a118bd2 100644
--- a/include/hw/boards.h
+++ b/include/hw/boards.h
@@ -176,12 +176,14 @@ struct MachineClass {
     void (*hot_add_cpu)(MachineState *state, const int64_t id, Error **errp);
     int (*kvm_type)(MachineState *machine, const char *arg);
     void (*smp_parse)(MachineState *ms, QemuOpts *opts);
+    int (*vcpu_parse)(MachineState *ms, QemuOpts *opts);
 
     BlockInterfaceType block_default_type;
     int units_per_default_bus;
     int max_cpus;
     int min_cpus;
     int default_cpus;
+    int vcpu_affinity[CPU_SETSIZE];
     unsigned int no_serial:1,
         no_parallel:1,
         no_floppy:1,
diff --git a/qemu-options.hx b/qemu-options.hx
index 292d4e7c0ce..1024c67ddf3 100644
--- a/qemu-options.hx
+++ b/qemu-options.hx
@@ -182,6 +182,16 @@ SRST
     hotpluggable CPUs.
 ERST
 
+DEF("vcpu", HAS_ARG, QEMU_OPTION_vcpu,
+    "-vcpu [vcpunum=]n[,affinity=affinity]\n"
+    "-vcpu [vcpunum=]n[,affinity=affinity]\n", QEMU_ARCH_ALL)
+STEXI
+@item -vcpu [vcpunum=]@var{n}[,affinity=@var{affinity}]
+@itemx -vcpu [vcpunum=]@var{n}[,affinity=@var{affinity}]
+@findex -vcpu
+VCPU Affinity. If specified, specify for all the CPUs.
+ETEXI
+
 DEF("numa", HAS_ARG, QEMU_OPTION_numa,
     "-numa node[,mem=size][,cpus=firstcpu[-lastcpu]][,nodeid=node][,initiator=node]\n"
     "-numa node[,memdev=id][,cpus=firstcpu[-lastcpu]][,nodeid=node][,initiator=node]\n"
diff --git a/softmmu/vl.c b/softmmu/vl.c
index 32c00478891..34406e320a0 100644
--- a/softmmu/vl.c
+++ b/softmmu/vl.c
@@ -1066,6 +1066,22 @@ static void configure_blockdev(BlockdevOptionsQueue *bdo_queue,
 
 }
 
+static QemuOptsList qemu_vcpu_opts = {
+    .name = "vcpu-opts",
+    .implied_opt_name = "vcpunum",
+    .head = QTAILQ_HEAD_INITIALIZER(qemu_vcpu_opts.head),
+    .desc = {
+        {
+            .name = "vcpunum",
+            .type = QEMU_OPT_NUMBER,
+        }, {
+            .name = "affinity",
+            .type = QEMU_OPT_NUMBER,
+        },
+        { /*End of list */ }
+    },
+};
+
 static QemuOptsList qemu_smp_opts = {
     .name = "smp-opts",
     .implied_opt_name = "cpus",
@@ -2016,6 +2032,14 @@ static inline bool nonempty_str(const char *str)
     return str && *str;
 }
 
+static int vl_parse_vcpu(void *opaque, QemuOpts *opts, Error **errp)
+{
+    MachineState *ms = opaque;
+    MachineClass *mc = MACHINE_GET_CLASS(ms);
+
+    return mc->vcpu_parse(ms, opts);
+}
+
 static int parse_fw_cfg(void *opaque, QemuOpts *opts, Error **errp)
 {
     gchar *buf;
@@ -2888,6 +2912,7 @@ void qemu_init(int argc, char **argv, char **envp)
     qemu_add_opts(&qemu_accel_opts);
     qemu_add_opts(&qemu_mem_opts);
     qemu_add_opts(&qemu_smp_opts);
+    qemu_add_opts(&qemu_vcpu_opts);
     qemu_add_opts(&qemu_boot_opts);
     qemu_add_opts(&qemu_add_fd_opts);
     qemu_add_opts(&qemu_object_opts);
@@ -3514,6 +3539,12 @@ void qemu_init(int argc, char **argv, char **envp)
                     exit(1);
                 }
                 break;
+            case QEMU_OPTION_vcpu:
+                if (!qemu_opts_parse_noisily(qemu_find_opts("vcpu-opts"),
+                                             optarg, true)) {
+                    exit(1);
+                }
+                break;
             case QEMU_OPTION_vnc:
                 vnc_parse(optarg, &error_fatal);
                 break;
@@ -3982,6 +4013,10 @@ void qemu_init(int argc, char **argv, char **envp)
         object_register_sugar_prop("memory-backend", "prealloc", "on");
     }
 
+    if (qemu_opts_foreach(qemu_find_opts("vcpu-opts"), vl_parse_vcpu, current_machine, NULL)) {
+        exit(1);
+    }
+
     /*
      * Get the default machine options from the machine if it is not already
      * specified either by the configuration file or by the command line.

From 1ce70fe2655588590ed5f10c20d238b763a9a7ed Mon Sep 17 00:00:00 2001
From: Christian Holzberger <ch@mosaiksoftware.de>
Date: Fri, 24 Apr 2020 05:45:43 +0200
Subject: [PATCH 4/4] Remove STEXI code from options

---
 qemu-options.hx | 10 ++++------
 1 file changed, 4 insertions(+), 6 deletions(-)

diff --git a/qemu-options.hx b/qemu-options.hx
index 1024c67ddf3..dc4791f1340 100644
--- a/qemu-options.hx
+++ b/qemu-options.hx
@@ -185,12 +185,10 @@ ERST
 DEF("vcpu", HAS_ARG, QEMU_OPTION_vcpu,
     "-vcpu [vcpunum=]n[,affinity=affinity]\n"
     "-vcpu [vcpunum=]n[,affinity=affinity]\n", QEMU_ARCH_ALL)
-STEXI
-@item -vcpu [vcpunum=]@var{n}[,affinity=@var{affinity}]
-@itemx -vcpu [vcpunum=]@var{n}[,affinity=@var{affinity}]
-@findex -vcpu
-VCPU Affinity. If specified, specify for all the CPUs.
-ETEXI
+SRST
+``-vcpu [vcpunum=]@var{n}[,affinity=@var{affinity}]``
+	VCPU Affinity. If specified, specify for all the CPUs.
+ERST
 
 DEF("numa", HAS_ARG, QEMU_OPTION_numa,
     "-numa node[,mem=size][,cpus=firstcpu[-lastcpu]][,nodeid=node][,initiator=node]\n"
